{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import ImageEnhance\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import softmax\n",
    "from torch.optim import Adam,lr_scheduler\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from utils_d import *\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(r'E:\\codes\\python\\area51m\\pytorch_deeplab_xception')\n",
    "\n",
    "from pytorch_deeplab_xception.modeling import deeplab\n",
    "\n",
    "os.environ['TORCH_HOME'] = r'E:\\data\\MODELS' #setting the environment variable\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'E:\\UCL\\Dissertation\\label\\input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (900,900)\n",
    "image_size_detail = (400,400)\n",
    "number_of_class_firstmodel = 8\n",
    "number_of_class_secondmodel = 2\n",
    "\n",
    "transform_deeplab = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "transform_deeplab_detail = transforms.Compose([transforms.Resize(image_size_detail),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])])\n",
    "\n",
    "dlab2 = deeplab.DeepLab(num_classes=number_of_class_firstmodel,backbone = 'resnet').to(device)\n",
    "\n",
    "dlab2.load_state_dict(torch.load(r'E:\\UCL\\Dissertation\\label\\trained_models\\model_deeplabv3+resnet_last_900.pt'))\n",
    "\n",
    "_ = dlab2.eval()\n",
    "\n",
    "for p in dlab2.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "dlab2_detail = deeplab.DeepLab(num_classes=number_of_class_secondmodel,backbone = 'resnet').to(device)\n",
    "\n",
    "dlab2_detail.load_state_dict(torch.load(r'E:\\UCL\\Dissertation\\label\\trained_models\\model_deeplabv3+resnet_amp_last_.pt'))\n",
    "\n",
    "for p in dlab2_detail.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "_ = dlab2_detail.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(img):\n",
    "    validation = transform_deeplab(img).unsqueeze(0).to(device)\n",
    "    res = dlab2(validation,interpolate = False)\n",
    "    res_ = F.interpolate(res,size = (img.size[1],img.size[0]),mode='bilinear', align_corners=False)\n",
    "    return torch.argmax(res_,dim = 1).squeeze(0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images = {}\n",
    "for imgname in file_names:\n",
    "    if imgname.endswith('.jpg') or imgname.endswith('.jpeg'):\n",
    "        img1 = Image.open(imgname)\n",
    "        if img1.size[0]<img1.size[1]:\n",
    "            #img1 = img1.rotate(-90,expand = True)\n",
    "            try:\n",
    "                predicted_images[imgname] = predict_(img1)\n",
    "            except:\n",
    "                predicted_images[imgname] = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_mask in predicted_images:\n",
    "    if predicted_images[each_mask] != 'none':\n",
    "        imgo = Image.open(each_mask)\n",
    "        imgon = np.array(imgo)\n",
    "        imgon[np.logical_not(predicted_images[each_mask].astype(bool))] = 0\n",
    "        Image.fromarray(imgon).save(r'E:\\UCL\\Dissertation\\3dmodel\\masks2\\{0}'.format(each_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = (255,0,0)\n",
    "green = (0,255,0)\n",
    "blue = (0,0,255)\n",
    "yellow = (255,225,0)\n",
    "orange = (255,125,0)\n",
    "purple = (155,0,255)\n",
    "greenblue = (0,255,225)\n",
    "pink = (255,140,248)\n",
    "colors = [red,green,blue,yellow,orange,purple,greenblue,pink]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\cx\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for each_mask in predicted_images:\n",
    "    if predicted_images[each_mask] != 'none':\n",
    "        converted = Image.fromarray(decode_color(predicted_images[each_mask],colors).astype(np.uint8))\n",
    "        converted.save(r'E:\\UCL\\Dissertation\\3dmodel\\mask3\\{0}'.format(each_mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
